{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Part2-Face-Mask_Detector.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"1xs2ZWINpuvV"},"source":["**Please open with Jupyter notebook.\n","Because COLAB can't access the webcam by OpenCV.**"]},{"cell_type":"code","metadata":{"id":"sbAZl_RzFYgs"},"source":["import cv2\n","import numpy as np\n","from keras.models import load_model\n","\n","## We load the model\n","model=load_model(\"./model/face_mask_detector_model.h5\")\n","\n","results={0:'NO MASK', 1:'MASK'}\n","colors={0:(0,0,255), 1:(0,255,0)} #color\n","\n","rect_size = 4\n","\n","# Use camera 0\n","cap = cv2.VideoCapture(0) \n","\n","# We load the xml file\n","haarcascade = cv2.CascadeClassifier('./face_detector/haarcascade_frontalface_default.xml')\n","\n","while True:    \n","    # image capture\n","    (rval, image) = cap.read()\n","    \n","    #Flip to act as a mirror\n","    image = cv2.flip(image,1,1) \n","    \n","    # print our group name\n","    cv2.rectangle(image,\n","                  (0,0),\n","                  (640,35),\n","                  (245, 165, 66),\n","                  -1)\n","    cv2.putText(image,\n","                'NeuralBit, PUC',\n","                (10, 25),\n","                cv2.FONT_HERSHEY_SIMPLEX,\n","                0.8,\n","                (255,255,255),\n","                2)\n","    \n","    # Resize the image to speed up detection\n","    rerect_size = cv2.resize(image,\n","                             (image.shape[1] // rect_size,\n","                              image.shape[0] // rect_size))\n","    \n","    # detect MultiScale / faces \n","    faces = haarcascade.detectMultiScale(rerect_size)\n","    \n","    # Draw rectangles around each face\n","    for f in faces:\n","        #Scale the shapesize backup\n","        (x, y, w, h) = [v * rect_size for v in f] \n","        #Scale the shapesize backup\n","        face_img = image[y:y+h, x:x+w]\n","        rerect_sized = cv2.resize(face_img,(150,150))\n","        normalized = rerect_sized/255.0\n","        reshaped = np.reshape(normalized,(1,150,150,3))\n","        reshaped = np.vstack([reshaped])\n","        \n","        # prediction\n","        result=model.predict(reshaped)\n","        accu = round(np.max(result)*100, 2)\n","        \n","        label = np.argmax(result,axis=1)[0] \n","      \n","        cv2.rectangle(image, (x,y), (x+w,y+h), colors[label],1) #rectangle on face\n","        cv2.rectangle(image, (x,y-30), (x+w,y), colors[label],-1) #label_background\n","        cv2.putText(image, results[label]+' '+str(accu)+'%', (x+5, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,255,255),1)\n","    \n","    # Show the image\n","    cv2.imshow('NeuralBit | Face Mask Detector',   image)\n","    # Press Q on keyboard to exit window\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# Stop video\n","cap.release()\n","# Close all started windows\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bH9O-NiMFYgy"},"source":[""],"execution_count":null,"outputs":[]}]}